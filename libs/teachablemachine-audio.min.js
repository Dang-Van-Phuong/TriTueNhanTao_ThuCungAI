/*! @teachablemachine/audio v0.8.4 */
var tmAudio = tmAudio || {};

(function(){
  tmAudio.load = async function(modelUrl, metadataUrl) {
    // Load metadata
    let metadata;
    if (metadataUrl) {
      metadata = await fetch(metadataUrl).then(res => res.json());
    } else {
      metadata = await fetch(modelUrl.replace("model.json", "metadata.json")).then(res => res.json());
    }

    const labels = metadata.labels;
    const inputShape = metadata.inputShape || [1, 43, 1024, 1];
    const spectrogramFrameSize = metadata.frameSize || 43;
    const fftSize = metadata.fftSize || 1024;

    // Load the model
    const model = await tf.loadLayersModel(modelUrl);

    let listening = false;
    let audioContext, analyser, source;

    async function listen(callback, options = {}) {
      if (listening) return;
      listening = true;

      const { probabilityThreshold = 0.0, overlapFactor = 0.5 } = options;
      const intervalTime = 1000 * (1 - overlapFactor);

      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = fftSize;
      source.connect(analyser);

      const freqData = new Float32Array(analyser.frequencyBinCount);

      const loop = () => {
        if (!listening) return;

        analyser.getFloatFrequencyData(freqData);

        // Convert to spectrogram matrix shape [1, 43, 1024, 1]
        const chunkSize = Math.floor(freqData.length / spectrogramFrameSize);
        let spectrogram = [];
        for (let i = 0; i < spectrogramFrameSize; i++) {
          spectrogram.push(freqData.slice(i * chunkSize, (i + 1) * chunkSize));
        }

        const inputTensor = tf.tensor4d(spectrogram, inputShape);

        const pred = model.predict(inputTensor).dataSync();

        inputTensor.dispose();

        let results = labels.map((label, i) => ({
          className: label,
          probability: pred[i]
        })).filter(r => r.probability >= probabilityThreshold);

        callback(results);

        setTimeout(loop, intervalTime);
      };

      loop();
    }

    async function stopListening() {
      listening = false;
      try {
        if (audioContext && audioContext.state !== "closed") {
          await audioContext.close();
        }
      } catch (e) {}
    }

    return { listen, stopListening, model, metadata, labels };
  };
})();
